# Endpoint for P2P node to listen on
# p2p-endpoint =

# Maxmimum number of incoming connections on P2P endpoint
# p2p-max-connections =

# P2P nodes to connect to on startup (may specify multiple times)
# p2p-seed-node =

# Pairs of [BLOCK_NUM,BLOCK_ID] that should be enforced as checkpoints.
# checkpoint =

# Number of threads for rpc-clients. Optimal value `<number of CPU>-1`
webserver-thread-pool-size = 2

# IP:PORT for HTTP connections
webserver-http-endpoint = 0.0.0.0:8090

# IP:PORT for WebSocket connections
webserver-ws-endpoint = 0.0.0.0:8091

# Maximum microseconds for trying to get read lock
read-wait-micro = 500000

# Maximum retries to get read lock. Each retry is read-wait-micro microseconds.
# When all retries are made, the rpc-client receives error 'Unable to acquire READ lock'.
max-read-wait-retries = 2

# Maximum microseconds for trying to get write lock on broadcast transaction.
write-wait-micro = 500000

# Maximum retries to get write lock. Each retry is write-wait-micro microseconds.
# When all retries are made, the rpc-client receives error 'Unable to acquire WRITE lock'.
max-write-wait-retries = 3

# Do all write operations (push_block/push_transaction) in the single thread.
# Write lock of database is very heavy. When many threads tries to lock database on writing, rpc-clients
# receive many errors 'Unable to acquire READ lock' ('Unable to acquire WRITE lock').
# Enabling of this options can increase performance.
single-write-thread = true

# Enable plugin notifications about operations in a pushed transaction, which should be included to the next generated
# block. Plugins doesn't validate data in operations, they only update its own indexes, so notifications can be
# disabled on push_transaction() without any side-effects. The option doesn't have effect on a pushing signed blocks,
# so it is safe.
# Disabling of this option can increase performance.
enable-plugins-on-push-transaction = true

# A start size for shared memory file when it doesn't have any data. Possible cases:
# - If shared memory has data and the value is greater then the size of shared_memory.bin,
#   the file will be grown to requested size.
# - If shared memory has data and the value is less then the size of shared_memory.bin, nothing happens.
# Changing of this parameter doesn't require the replaying.
shared-file-size = 100M

# The minimum free space in the shared memory file. When free space reaches the following value, the size of the
# shared_memory.bin increases by the value of inc-shared-file-size.
min-free-shared-file-size = 50M

# Step of increasing size of shared_memory.bin. When the free memory size reaches min-free-shared-file-size,
# the shared memory size increases by the following value.
inc-shared-file-size = 100M

# How often do checking the free space in shared_memory.bin. A very frequent checking can decrease performance.
# It's not critical if the free size became very small, because the daemon catches the `bad_alloc` exception
# and resizes. The optimal strategy is do checking of the free space, but not very often.
block-num-check-free-size = 10 # each 30 seconds

plugin = chain p2p json_rpc webserver network_broadcast_api witness test_api database_api private_message follow social_network tags market_history account_by_key account_history operation_history statsd block_info raw_block debug_node witness_api mongo_db

# For connect to mongodb which is running outside Docker (if golosd running inside)
mongodb-uri = mongodb://172.17.0.1:27017/Golos

# Remove votes before defined block, should increase performance
clear-votes-before-block = 0 # don't clear votes

# If set, remove votes older than specified number of blocks.
#   -1 = do not remove;
#   0 = remove after cashout;
#   any other value N - remove votes older than N blocks.
# Note: votes don't removed before post cashout
# clear-votes-older-n-blocks = 0

# Store account metadata for all accounts if true, for no one if else.
# store-account-metadata = true

# Names of accounts to store metadata
# store-account-metadata-list =

# Store memo for all savings withdraws
# store-memo-in-savings-withdraws = true

# If set, remove comment titles older than specified number of blocks.
# comment-title-depth =

# If set, remove comment bodies older than specified number of blocks.
# comment-body-depth =

# If set, remove comment json-metadatas older than specified number of blocks.
# comment-json-metadata-depth =

# should content's depth be set to null after update
# set-content-storing-depth-null-after-update = false

# Mode of storing records of comment.active and comment.last_update:
#    -1 = store all
#    0 = do not store
#    N = storing N blocks depth
# comment-last-update-depth = -1

# Store comment rewards
# store-comment-rewards = true

# Replay all blocks if shared memory is corrupted
replay-if-corrupted = true

# Virtual operations will not be passed to the plugins, enabling of the option helps to save some memory.
skip-virtual-ops = false

# Defines a range of accounts to track by the account_history plugin as a json pair ["from","to"] [from,to]
# track-account-range =

# Defines a list of operations which will be explicitly logged by the account_history plugin.
# history-whitelist-ops =

# Defines a list of operations which will be explicitly ignored by the account_history plugin.
# history-blacklist-ops =

# Defines starting block from which recording stats by the account_history plugin.
# history-start-block =

# Set maximum number of parsing tags
tags-number = 5

# Set maximum length of tag
tag-max-length = 512

# Set the maximum size of cached feed for an account
follow-max-feed-size = 500

# Track market history by grouping orders into buckets of equal size measured in seconds specified as a JSON array of numbers
bucket-size = [15,60,300,3600,86400]

# How far back in time to track history for each bucket size, measured in the number of buckets (default: 5760)
history-per-size = 5760

# Defines a range of accounts to private messages to/from as a json pair ["from","to"] [from,to)
# pm-account-range =

# Defines a list of accounts to private messages to/from
# pm-account-list =

# Enable block production, even if the chain is stale.
enable-stale-production = true

# Percent of witnesses (0-99) that must be participating in order to produce blocks
required-participation = 0

# name of witness controlled by this node (e.g. initwitness )
witness = "cyberfounder"

# name of miner and its private key (e.g. ["account","WIF PRIVATE KEY"] )
miner = ["cyberfounder","5JVFFWRLwz6JoP9kguuRFfytToGU6cLgBVTL9t6NB3D3BQLbUBS"]

# Number of threads to use for proof of work mining
mining-threads = 1

# WIF PRIVATE KEY to be used by one or more witnesses or miners
private-key = 5JVFFWRLwz6JoP9kguuRFfytToGU6cLgBVTL9t6NB3D3BQLbUBS

# Account creation fee to be voted on upon successful POW - Minimum fee is 100.000 STEEM (written as 100000)
# miner-account-creation-fee =

# Maximum block size (in bytes) to be voted on upon successful POW - Max block size must be between 128 KB and 750 MB
# miner-maximum-block-size =

# SBD interest rate to be vote on upon successful POW - Default interest rate is 10% (written as 1000)
# miner-sbd-interest-rate =

# declare an appender named "stderr" that writes messages to the console
[log.console_appender.stderr]
stream=std_error

# declare an appender named "p2p" that writes messages to p2p.log
[log.file_appender.p2p]
filename=logs/p2p/p2p.log
# filename can be absolute or relative to this config file

# route any messages logged to the default logger to the "stderr" logger we
# declared above, if they are info level are higher
[logger.default]
level=info
appenders=stderr

# route messages sent to the "p2p" logger to stderr too
[logger.p2p]
level=info
appenders=stderr
